{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-machine-learning/resources/bANLa) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4 - Understanding and Predicting Property Maintenance Fines\n",
    "\n",
    "This assignment is based on a data challenge from the Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)). \n",
    "\n",
    "The Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)) and the Michigan Student Symposium for Interdisciplinary Statistical Sciences ([MSSISS](https://sites.lsa.umich.edu/mssiss/)) have partnered with the City of Detroit to help solve one of the most pressing problems facing Detroit - blight. [Blight violations](http://www.detroitmi.gov/How-Do-I/Report/Blight-Complaint-FAQs) are issued by the city to individuals who allow their properties to remain in a deteriorated condition. Every year, the city of Detroit issues millions of dollars in fines to residents and every year, many of these fines remain unpaid. Enforcing unpaid blight fines is a costly and tedious process, so the city wants to know: how can we increase blight ticket compliance?\n",
    "\n",
    "The first step in answering this question is understanding when and why a resident might fail to comply with a blight ticket. This is where predictive modeling comes in. For this assignment, your task is to predict whether a given blight ticket will be paid on time.\n",
    "\n",
    "All data for this assignment has been provided to us through the [Detroit Open Data Portal](https://data.detroitmi.gov/). **Only the data already included in your Coursera directory can be used for training the model for this assignment.** Nonetheless, we encourage you to look into data from other Detroit datasets to help inform feature creation and model selection. We recommend taking a look at the following related datasets:\n",
    "\n",
    "* [Building Permits](https://data.detroitmi.gov/Property-Parcels/Building-Permits/xw2a-a7tf)\n",
    "* [Trades Permits](https://data.detroitmi.gov/Property-Parcels/Trades-Permits/635b-dsgv)\n",
    "* [Improve Detroit: Submitted Issues](https://data.detroitmi.gov/Government/Improve-Detroit-Submitted-Issues/fwz3-w3yn)\n",
    "* [DPD: Citizen Complaints](https://data.detroitmi.gov/Public-Safety/DPD-Citizen-Complaints-2016/kahe-efs3)\n",
    "* [Parcel Map](https://data.detroitmi.gov/Property-Parcels/Parcel-Map/fxkw-udwf)\n",
    "\n",
    "___\n",
    "\n",
    "We provide you with two data files for use in training and validating your models: train.csv and test.csv. Each row in these two files corresponds to a single blight ticket, and includes information about when, why, and to whom each ticket was issued. The target variable is compliance, which is True if the ticket was paid early, on time, or within one month of the hearing data, False if the ticket was paid after the hearing date or not at all, and Null if the violator was found not responsible. Compliance, as well as a handful of other variables that will not be available at test-time, are only included in train.csv.\n",
    "\n",
    "Note: All tickets where the violators were found not responsible are not considered during evaluation. They are included in the training set as an additional source of data for visualization, and to enable unsupervised and semi-supervised approaches. However, they are not included in the test set.\n",
    "\n",
    "<br>\n",
    "\n",
    "**File descriptions** (Use only this data for training your model!)\n",
    "\n",
    "    train.csv - the training set (all tickets issued 2004-2011)\n",
    "    test.csv - the test set (all tickets issued 2012-2016)\n",
    "    addresses.csv & latlons.csv - mapping from ticket id to addresses, and from addresses to lat/lon coordinates. \n",
    "     Note: misspelled addresses may be incorrectly geolocated.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv\n",
    "\n",
    "    ticket_id - unique identifier for tickets\n",
    "    agency_name - Agency that issued the ticket\n",
    "    inspector_name - Name of inspector that issued the ticket\n",
    "    violator_name - Name of the person/organization that the ticket was issued to\n",
    "    violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred\n",
    "    mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator\n",
    "    ticket_issued_date - Date and time the ticket was issued\n",
    "    hearing_date - Date and time the violator's hearing was scheduled\n",
    "    violation_code, violation_description - Type of violation\n",
    "    disposition - Judgment and judgement type\n",
    "    fine_amount - Violation fine amount, excluding fees\n",
    "    admin_fee - $20 fee assigned to responsible judgments\n",
    "state_fee - $10 fee assigned to responsible judgments\n",
    "    late_fee - 10% fee assigned to responsible judgments\n",
    "    discount_amount - discount applied, if any\n",
    "    clean_up_cost - DPW clean-up or graffiti removal cost\n",
    "    judgment_amount - Sum of all fines and fees\n",
    "    grafitti_status - Flag for graffiti violations\n",
    "    \n",
    "train.csv only\n",
    "\n",
    "    payment_amount - Amount paid, if any\n",
    "    payment_date - Date payment was made, if it was received\n",
    "    payment_status - Current payment status as of Feb 1 2017\n",
    "    balance_due - Fines and fees still owed\n",
    "    collection_status - Flag for payments in collections\n",
    "    compliance [target variable for prediction] \n",
    "     Null = Not responsible\n",
    "     0 = Responsible, non-compliant\n",
    "     1 = Responsible, compliant\n",
    "    compliance_detail - More information on why each ticket was marked compliant or non-compliant\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Your predictions will be given as the probability that the corresponding blight ticket will be paid on time.\n",
    "\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC). \n",
    "\n",
    "Your grade will be based on the AUC score computed for your classifier. A model which with an AUROC of 0.7 passes this assignment, over 0.75 will recieve full points.\n",
    "___\n",
    "\n",
    "For this assignment, create a function that trains a model to predict blight ticket compliance in Detroit using `train.csv`. Using this model, return a series of length 61001 with the data being the probability that each corresponding ticket from `test.csv` will be paid, and the index being the ticket_id.\n",
    "\n",
    "Example:\n",
    "\n",
    "    ticket_id\n",
    "       284932    0.531842\n",
    "       285362    0.401958\n",
    "       285361    0.105928\n",
    "       285338    0.018572\n",
    "                 ...\n",
    "       376499    0.208567\n",
    "       376500    0.818759\n",
    "       369851    0.018528\n",
    "       Name: compliance, dtype: float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading graphviz-0.8-py2.py3-none-any.whl\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.8\n"
     ]
    }
   ],
   "source": [
    "! pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agency_name distribution:\n",
      "Buildings, Safety Engineering & Env Department    95863\n",
      "Department of Public Works                        52445\n",
      "Health Department                                  7107\n",
      "Detroit Police Department                          4464\n",
      "Neighborhood City Halls                               1\n",
      "Name: agency_name, dtype: int64\n",
      "\n",
      "null: 0\n",
      "\n",
      "city distribution:\n",
      "DETROIT                87426\n",
      "SOUTHFIELD              8790\n",
      "Detroit                 6374\n",
      "DEARBORN                2408\n",
      "detroit                 2197\n",
      "FARMINGTON HILLS        1468\n",
      "OAK PARK                1436\n",
      "WARREN                  1235\n",
      "W. BLOOMFIELD           1033\n",
      "DET                     1010\n",
      "REDFORD                  951\n",
      "TROY                     888\n",
      "LIVONIA                  784\n",
      "WEST BLOOMFIELD          724\n",
      "Southfield               687\n",
      "CANTON                   642\n",
      "FARMINGTON               591\n",
      "BLOOMFIELD HILLS         587\n",
      "CHICAGO                  564\n",
      "DET.                     546\n",
      "SAN DIEGO                538\n",
      "EASTPOINTE               537\n",
      "ROSEVILLE                502\n",
      "GROSSE POINTE            483\n",
      "GILBERT                  480\n",
      "LATHRUP VILLAGE          471\n",
      "LANSING                  438\n",
      "FERNDALE                 432\n",
      "WESTLAND                 427\n",
      "ST. CLAIR SHORES         418\n",
      "                       ...  \n",
      "OAK FIELD                  1\n",
      "GENEVA                     1\n",
      "Dacuia                     1\n",
      "HARRISON TOPWNSHIP         1\n",
      "GLEN ROCK                  1\n",
      "LOTHRUP                    1\n",
      "ST.CLAIR  SHORES           1\n",
      "barryton                   1\n",
      "N. RICHLAND HILLS          1\n",
      "INDIANAPOLIA               1\n",
      "AMMAN                      1\n",
      "WCEGA TOWER 03-74          1\n",
      "DEARBORH HEIGHTS           1\n",
      "MULBURRY                   1\n",
      "N. LAS VEGAS               1\n",
      "BLOOMFIELD HILSS           1\n",
      "gspf                       1\n",
      "harrisburg                 1\n",
      "ROOKWOOD                   1\n",
      "CLARKSVILLE                1\n",
      "WOODHAVER                  1\n",
      "BLOOMFIELD HILLS-ST        1\n",
      "Grosse Pte Park            1\n",
      "ROBINA  QLD                1\n",
      "SEBASTIAN                  1\n",
      "Brownstone                 1\n",
      "ALAMOGORDO                 1\n",
      "OAR PARK                   1\n",
      "DEtroit                    1\n",
      "GROSSPOINTE                1\n",
      "Name: city, Length: 4093, dtype: int64\n",
      "\n",
      "null: 0\n",
      "\n",
      "violation_code distribution:\n",
      "9-1-36(a)               64414\n",
      "9-1-81(a)               23145\n",
      "22-2-88                 19073\n",
      "9-1-104                 16927\n",
      "22-2-88(b)               4879\n",
      "22-2-45                  4200\n",
      "9-1-105                  3619\n",
      "9-1-110(a)               3147\n",
      "9-1-43(a) - (Dwellin     3043\n",
      "9-1-103(C)               2641\n",
      "22-2-22                  2612\n",
      "22-2-43                  2054\n",
      "19450901                 1620\n",
      "22-2-17                  1414\n",
      "22-2-61                   706\n",
      "22-2-83(a)(b)(c)          494\n",
      "9-1-82(d) - (Dwellin      457\n",
      "61-81.0100/32.0066        439\n",
      "9-1-43(a) - (Structu      399\n",
      "22-2-83                   347\n",
      "22-2-88(a)                235\n",
      "9-1-206                   235\n",
      "61-5-21                   202\n",
      "9-1-209                   200\n",
      "22-2-21(b)                185\n",
      "9-1-101                   150\n",
      "9-1-107                   133\n",
      "9-1-43(a) - (Stories      132\n",
      "9-1-111                   130\n",
      "9-1-201(a)                128\n",
      "                        ...  \n",
      "9-1-219                     1\n",
      "61-120.0100/32.0066         1\n",
      "9-1-332                     1\n",
      "9-1-352                     1\n",
      "9-1-434                     1\n",
      "20160901                    1\n",
      "22-2-85                     1\n",
      "61-81.0100/45.0807          1\n",
      "9-1-353(2)                  1\n",
      "9-1-354                     1\n",
      "9-1-377                     1\n",
      "61-45.0000/45.0800          1\n",
      "9-1-310                     1\n",
      "61-104.0100                 1\n",
      "61-83.0100/32.0066          1\n",
      "9-1-443(b)                  1\n",
      "61-82.0100/32.0031          1\n",
      "9-1-502                     1\n",
      "22-2-49(b)                  1\n",
      "61-130.0000/130.0500        1\n",
      "9-1-474                     1\n",
      "61-84.0100/45.0807          1\n",
      "61-83.0100/32.0031          1\n",
      "61-4-35                     1\n",
      "61-86.0100/45.0807          1\n",
      "9-1-462(a)                  1\n",
      "22-2-84 (DO NOT USE         1\n",
      "9-1-406                     1\n",
      "61-114.0100                 1\n",
      "61-47.0000/47.0108          1\n",
      "Name: violation_code, Length: 189, dtype: int64\n",
      "\n",
      "null: 0\n",
      "\n",
      "disposition distribution:\n",
      "Responsible by Default                138340\n",
      "Responsible by Admission               13701\n",
      "Responsible by Determination            7644\n",
      "Responsible (Fine Waived) by Deter       195\n",
      "Name: disposition, dtype: int64\n",
      "\n",
      "null: 0\n",
      "\n",
      "judgment_amount distribution:\n",
      "305.0      79621\n",
      "85.0       17655\n",
      "140.0      12516\n",
      "250.0      11355\n",
      "280.0       7177\n",
      "580.0       6545\n",
      "1130.0      4803\n",
      "3880.0      3785\n",
      "360.0       3680\n",
      "130.0       2972\n",
      "80.0        2760\n",
      "2780.0      1506\n",
      "230.0       1356\n",
      "57.5        1223\n",
      "167.5        723\n",
      "530.0        373\n",
      "1680.0       251\n",
      "855.0        217\n",
      "0.0          195\n",
      "11030.0      195\n",
      "1030.0       162\n",
      "55.0         155\n",
      "415.0        126\n",
      "330.0         88\n",
      "5530.0        85\n",
      "3530.0        74\n",
      "155.0         70\n",
      "1350.0        40\n",
      "2530.0        39\n",
      "470.0         36\n",
      "2230.0        14\n",
      "7730.0        13\n",
      "1530.0        13\n",
      "780.0         12\n",
      "690.0         10\n",
      "3330.0         4\n",
      "430.0          3\n",
      "272.0          3\n",
      "134.5          2\n",
      "2030.0         2\n",
      "206.0          2\n",
      "1955.0         2\n",
      "380.0          2\n",
      "1405.0         2\n",
      "774.7          1\n",
      "1060.0         1\n",
      "180.0          1\n",
      "195.0          1\n",
      "8830.0         1\n",
      "1097.0         1\n",
      "50.0           1\n",
      "300.0          1\n",
      "2994.5         1\n",
      "525.0          1\n",
      "217.0          1\n",
      "750.5          1\n",
      "31.1           1\n",
      "Name: judgment_amount, dtype: int64\n",
      "\n",
      "null: 0\n",
      "\n",
      "address distribution:\n",
      "600 woodward ave, Detroit MI        52\n",
      "16189 schaefer, Detroit MI          50\n",
      "4471 parkinson, Detroit MI          42\n",
      "935 louisiana, Detroit MI           35\n",
      "3900 outer drive, Detroit MI        33\n",
      "9125 jefferson, Detroit MI          33\n",
      "53 marston, Detroit MI              32\n",
      "59 seward, Detroit MI               32\n",
      "473 chalmers, Detroit MI            31\n",
      "18397 appleton, Detroit MI          29\n",
      "1442 calvert, Detroit MI            28\n",
      "1514 washington blvd, Detroit MI    27\n",
      "4800 fort st, Detroit MI            27\n",
      "8430 jefferson, Detroit MI          26\n",
      "525 brentwood, Detroit MI           26\n",
      "13602 eastwood, Detroit MI          26\n",
      "8100 jefferson, Detroit MI          25\n",
      "14340 puritan, Detroit MI           25\n",
      "18055 schoenherr, Detroit MI        24\n",
      "14362 evergreen, Detroit MI         24\n",
      "6339 woodhall, Detroit MI           24\n",
      "6817 grandville, Detroit MI         23\n",
      "13641 hasse, Detroit MI             23\n",
      "400 bagley, Detroit MI              23\n",
      "16211 schaefer, Detroit MI          23\n",
      "1509 holcomb, Detroit MI            21\n",
      "19136 runyon, Detroit MI            21\n",
      "9757 lakepointe, Detroit MI         21\n",
      "69 seward, Detroit MI               21\n",
      "18430 bloom, Detroit MI             20\n",
      "                                    ..\n",
      "2255 ferry, Detroit MI               1\n",
      "19200 winthrop, Detroit MI           1\n",
      "19759 pennington, Detroit MI         1\n",
      "14842 seven mile, Detroit MI         1\n",
      "12751 alcoy, Detroit MI              1\n",
      "5865 lumley, Detroit MI              1\n",
      "8276 carbondale, Detroit MI          1\n",
      "4647 wesson, Detroit MI              1\n",
      "3627 lincoln, Detroit MI             1\n",
      "10017 pierson, Detroit MI            1\n",
      "19378 grandville, Detroit MI         1\n",
      "2940 dartmouth, Detroit MI           1\n",
      "5364 ivanhoe, Detroit MI             1\n",
      "16510 woodingham, Detroit MI         1\n",
      "9092 longacre, Detroit MI            1\n",
      "2044 clayton, Detroit MI             1\n",
      "15258 eastwood, Detroit MI           1\n",
      "19917 rowe, Detroit MI               1\n",
      "3347 mclean, Detroit MI              1\n",
      "15700 hubbell, Detroit MI            1\n",
      "14160 braile, Detroit MI             1\n",
      "17117 gilchrist, Detroit MI          1\n",
      "7297 penrod, Detroit MI              1\n",
      "7727 navy, Detroit MI                1\n",
      "8890 livernois, Detroit MI           1\n",
      "6338 lambert, Detroit MI             1\n",
      "19122 mcnichols, Detroit MI          1\n",
      "20159 van dyke, Detroit MI           1\n",
      "18301 lahser, Detroit MI             1\n",
      "5261 kensington, Detroit MI          1\n",
      "Name: address, Length: 71901, dtype: int64\n",
      "\n",
      "null: 0\n",
      "\n",
      "lat distribution:\n",
      "42.377249    387\n",
      "42.341729    355\n",
      "42.341730    329\n",
      "42.410855    264\n",
      "42.352331    248\n",
      "42.407284    233\n",
      "42.349328    116\n",
      "42.410644    107\n",
      "42.348420     86\n",
      "42.350713     86\n",
      "42.428686     75\n",
      "42.330486     52\n",
      "42.410737     50\n",
      "42.330728     42\n",
      "42.422387     35\n",
      "42.284349     33\n",
      "42.439710     33\n",
      "42.375509     32\n",
      "42.374401     32\n",
      "42.334911     32\n",
      "42.366236     31\n",
      "42.424067     29\n",
      "42.385032     28\n",
      "42.433052     28\n",
      "42.310855     27\n",
      "42.353032     26\n",
      "42.431137     26\n",
      "42.432855     26\n",
      "42.411105     25\n",
      "42.406626     25\n",
      "            ... \n",
      "42.441003      1\n",
      "42.361895      1\n",
      "42.430063      1\n",
      "42.446529      1\n",
      "42.333462      1\n",
      "42.353876      1\n",
      "42.364645      1\n",
      "42.351650      1\n",
      "42.365492      1\n",
      "42.413000      1\n",
      "42.363806      1\n",
      "42.341941      1\n",
      "42.376856      1\n",
      "42.390322      1\n",
      "42.386133      1\n",
      "42.408435      1\n",
      "42.408641      1\n",
      "42.337779      1\n",
      "42.358794      1\n",
      "42.449385      1\n",
      "42.398375      1\n",
      "42.439568      1\n",
      "42.348564      1\n",
      "42.422865      1\n",
      "42.422573      1\n",
      "42.445379      1\n",
      "42.365891      1\n",
      "42.313912      1\n",
      "42.374168      1\n",
      "42.424247      1\n",
      "Name: lat, Length: 61559, dtype: int64\n",
      "\n",
      "null: 2\n",
      "\n",
      "132052     89535\n",
      "227181    223598\n",
      "Name: ticket_id, dtype: int64\n",
      "lon distribution:\n",
      "-83.238943    387\n",
      "-83.262245    355\n",
      "-83.262271    329\n",
      "-83.046409    264\n",
      "-83.252023    248\n",
      "-83.277150    233\n",
      "-83.256895    116\n",
      "-83.136195    107\n",
      "-83.257840     86\n",
      "-83.255176     86\n",
      "-83.284184     75\n",
      "-83.045493     52\n",
      "-83.179868     50\n",
      "-83.131715     42\n",
      "-83.093353     35\n",
      "-83.035374     33\n",
      "-83.124639     33\n",
      "-83.077292     32\n",
      "-83.075551     32\n",
      "-82.940525     31\n",
      "-83.274162     29\n",
      "-83.098879     28\n",
      "-83.109516     27\n",
      "-83.050357     27\n",
      "-83.094539     27\n",
      "-82.984740     27\n",
      "-82.989770     26\n",
      "-83.236577     25\n",
      "-82.992903     25\n",
      "-82.933072     24\n",
      "             ... \n",
      "-82.989454      1\n",
      "-83.088068      1\n",
      "-82.943309      1\n",
      "-82.991884      1\n",
      "-83.023037      1\n",
      "-83.084483      1\n",
      "-83.079996      1\n",
      "-83.210643      1\n",
      "-83.269211      1\n",
      "-83.025368      1\n",
      "-83.072443      1\n",
      "-83.132119      1\n",
      "-83.104186      1\n",
      "-83.216927      1\n",
      "-83.145141      1\n",
      "-83.041680      1\n",
      "-83.242100      1\n",
      "-83.079152      1\n",
      "-82.951234      1\n",
      "-83.023032      1\n",
      "-83.087602      1\n",
      "-82.961487      1\n",
      "-83.183436      1\n",
      "-83.234650      1\n",
      "-82.960516      1\n",
      "-82.970848      1\n",
      "-83.185355      1\n",
      "-83.152992      1\n",
      "-83.232647      1\n",
      "-83.083605      1\n",
      "Name: lon, Length: 66839, dtype: int64\n",
      "\n",
      "null: 2\n",
      "\n",
      "132052     89535\n",
      "227181    223598\n",
      "Name: ticket_id, dtype: int64\n",
      "ticket_issued_days_to_2004 distribution:\n",
      "7247.0    451\n",
      "7670.0    359\n",
      "6128.0    303\n",
      "6334.0    292\n",
      "6428.0    283\n",
      "6710.0    273\n",
      "7564.0    261\n",
      "7241.0    256\n",
      "7340.0    253\n",
      "7381.0    243\n",
      "7563.0    240\n",
      "7264.0    239\n",
      "7578.0    238\n",
      "7479.0    230\n",
      "7606.0    230\n",
      "7430.0    228\n",
      "7465.0    225\n",
      "7122.0    224\n",
      "7248.0    221\n",
      "6604.0    221\n",
      "6404.0    221\n",
      "7438.0    220\n",
      "7444.0    218\n",
      "7102.0    217\n",
      "6387.0    214\n",
      "6717.0    214\n",
      "7605.0    214\n",
      "7579.0    214\n",
      "7402.0    213\n",
      "7219.0    213\n",
      "         ... \n",
      "7805.0      1\n",
      "7343.0      1\n",
      "7679.0      1\n",
      "8015.0      1\n",
      "8295.0      1\n",
      "8400.0      1\n",
      "6349.0      1\n",
      "8043.0      1\n",
      "6397.0      1\n",
      "7826.0      1\n",
      "8393.0      1\n",
      "7176.0      1\n",
      "8415.0      1\n",
      "7890.0      1\n",
      "7180.0      1\n",
      "8637.0      1\n",
      "7742.0      1\n",
      "6573.0      1\n",
      "6104.0      1\n",
      "7385.0      1\n",
      "6329.0      1\n",
      "8059.0      1\n",
      "8058.0      1\n",
      "7873.0      1\n",
      "7386.0      1\n",
      "7945.0      1\n",
      "8630.0      1\n",
      "8050.0      1\n",
      "7204.0      1\n",
      "6018.0      1\n",
      "Name: ticket_issued_days_to_2004, Length: 2008, dtype: int64\n",
      "\n",
      "null: 0\n",
      "\n",
      "discount_percentage distribution:\n",
      "0.000000    158700\n",
      "0.089286       605\n",
      "0.062500       167\n",
      "0.076923       155\n",
      "0.086957       135\n",
      "0.094340        43\n",
      "0.054545        19\n",
      "0.090909        17\n",
      "0.097087        16\n",
      "0.099150        15\n",
      "0.098814         6\n",
      "0.093023         1\n",
      "0.083871         1\n",
      "Name: discount_percentage, dtype: int64\n",
      "\n",
      "null: 0\n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'y' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-57b49ff8c691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_work\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_work\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mX_work\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_work\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-57b49ff8c691>\u001b[0m in \u001b[0;36mimport_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnull_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticket_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y value distribution:\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnull_feature_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'y' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def import_data():\n",
    "    \n",
    "    feature_names = ['agency_name', 'violation_street_number', 'violation_street_name', 'violation_zip_code',\n",
    "                     'mailing_address_str_number', 'mailing_address_str_name', 'city', 'state', 'zip_code', 'non_us_str_code', 'country',\n",
    "                     'ticket_issued_date', 'hearing_date', 'violation_code', 'disposition',\n",
    "                     'fine_amount', 'admin_fee', 'state_fee', 'late_fee', 'discount_amount', 'clean_up_cost', 'judgment_amount', \n",
    "                     'grafitti_status', 'address', 'lat', 'lon']\n",
    "    \n",
    "    target_name = 'compliance'\n",
    "        \n",
    "    df_train = pd.read_csv('train.csv', encoding='cp1252', low_memory=False)\n",
    "    \n",
    "    df_add = pd.read_csv('addresses.csv', encoding='cp1252', low_memory=False)\n",
    "    \n",
    "    df_lat = pd.read_csv('latlons.csv', encoding='cp1252', low_memory=False)\n",
    "    \n",
    "    df_temp = df_train.merge(df_add, on='ticket_id')\n",
    "    \n",
    "    df = df_temp.merge(df_lat, on='address')\n",
    "    \n",
    "    df = df[df[target_name].notnull()]\n",
    "    \n",
    "    df['judgment_amount'] = df['judgment_amount'].astype(float)\n",
    "    \n",
    "    df['discount_percentage'] = df['discount_amount'].divide(df['judgment_amount']).replace(np.nan, 0)\n",
    "\n",
    "    df['ticket_issued_month'] = df['ticket_issued_date'].str.slice(stop=7)\n",
    "    \n",
    "    df['ticket_issued_date'] = pd.to_datetime(df['ticket_issued_date'])\n",
    "    \n",
    "    df['ticket_issued_days_to_2004'] = (df['ticket_issued_date'] - df['ticket_issued_date'].min()).astype('timedelta64[D]')\n",
    "                \n",
    "    calculated_feature_name = ['ticket_issued_days_to_2004', 'discount_percentage']\n",
    "        \n",
    "    working_feature_names = ['agency_name', 'city', 'violation_code', 'disposition', 'judgment_amount', 'address', 'lat', 'lon']\n",
    "        \n",
    "    working_feature_names += calculated_feature_name\n",
    "                \n",
    "    null_feature_set = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    for key in working_feature_names:\n",
    "        print(key + ' distribution:\\n' + str(df[key].value_counts()) + '\\n')\n",
    "        print(\"null: \" + str(df[key].isnull().sum()) + '\\n')\n",
    "        if df[key].isnull().sum() > 0:\n",
    "            null_items = df[df[key].isnull()]\n",
    "            null_feature_set.merge(null_items, on='ticket_id')\n",
    "            print(null_items['ticket_id'])\n",
    "        \n",
    "    df = df.drop(null_feature_set)\n",
    "        \n",
    "    X = df[feature_names + calculated_feature_name]\n",
    "    \n",
    "    y = df[target_name]\n",
    "    \n",
    "    print('y value distribution:\\n' + str(y.value_counts()))\n",
    "\n",
    "    \n",
    "    X_work, X_test, y_work, y_test = train_test_split(X, y, random_state=0, test_size=0.1)\n",
    "\n",
    "    return X_work, X_test, y_work, y_test, df\n",
    "\n",
    "X_work, X_test, y_work, y_test, df = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_scaler(X, working_features=None):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_norm = pd.DataFrame(scaler.fit_transform(X[working_features]), columns=working_features)\n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_auc(y_test, y_score):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlim([-0.01, 1.00])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.plot(fpr, tpr, lw=3, label='LogRegr ROC curve (area = {:0.2f})'.format(roc_auc))\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.title('ROC curve (1-of-10 digits classifier)', fontsize=16)\n",
    "    plt.legend(loc='lower right', fontsize=13)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "    plt.axes().set_aspect('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "def dummpy_classifier():\n",
    "# Negative class (0) is most frequent\n",
    "    working_features = ['discount_percentage', 'judgment_amount']\n",
    "    clf = DummyClassifier(strategy = 'most_frequent').fit(X_work[working_features], y_work)\n",
    "    # Therefore the dummy 'most_frequent' classifier always predicts class 0\n",
    "        \n",
    "    accuracy_score = clf.score(X_test[working_features], y_test)\n",
    "    \n",
    "    print('Dummy Classifier Score: {:.2f}'.format(accuracy_score)) \n",
    "    \n",
    "    return \n",
    "dummpy_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "import itertools\n",
    "\n",
    "def plot_test_2D(working_features, normalize=False):\n",
    "    \n",
    "    if normalize:\n",
    "        X = normalize_scaler(X_test, working_features=working_features)\n",
    "    else:\n",
    "        X = X_test\n",
    "        \n",
    "    feature_combo = list(itertools.combinations(working_features, 2))\n",
    "\n",
    "    fig, subaxes = plt.subplots(len(feature_combo), 1, figsize=(6,20))\n",
    "\n",
    "    if not hasattr(subaxes, '__iter__'):\n",
    "        subaxes = [subaxes]\n",
    "\n",
    "    for pair, axis in zip(feature_combo, subaxes):\n",
    "                \n",
    "        axis.scatter(X[pair[0]], X[pair[1]], c=y_test)\n",
    "        \n",
    "        axis.set_xlabel(pair[0])\n",
    "        axis.set_ylabel(pair[1])\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3ab3dcf14ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworking_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mclf_svm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworking_features_svm\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msimple_support_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3ab3dcf14ebb>\u001b[0m in \u001b[0;36msimple_support_vector\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mworking_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'discount_percentage'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'judgment_amount'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ticket_issued_days_to_2004'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_work\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworking_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworking_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_work\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7d2c85b2e221>\u001b[0m in \u001b[0;36mnormalize_scaler\u001b[0;34m(X, working_features)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize_scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworking_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mX_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworking_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworking_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sx5640/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sx5640/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sx5640/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         X = check_array(X, copy=self.copy, ensure_2d=False, warn_on_dtype=True,\n\u001b[0;32m--> 318\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sx5640/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sx5640/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def simple_support_vector():\n",
    "    working_features = ['discount_percentage', 'judgment_amount', 'ticket_issued_days_to_2004', 'lat', 'lon']\n",
    "    \n",
    "    X_norm = normalize_scaler(X_work, working_features=working_features)\n",
    "        \n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_norm, y_work, random_state=0, test_size=0.1)\n",
    "\n",
    "    X_train_small = X_train.iloc[::1]\n",
    "    \n",
    "    y_train_small = y_train.iloc[::1]\n",
    "    \n",
    "    clf = SVC().fit(X_train_small, y_train_small.as_matrix())\n",
    "    \n",
    "    y_decision_fn_scores = clf.decision_function(X_validation) \n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_validation, y_decision_fn_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plot_auc(y_validation, y_decision_fn_scores)\n",
    "\n",
    "    print('Validation set AUC: ', roc_auc)\n",
    "    \n",
    "    return clf, working_features\n",
    "\n",
    "clf_svm, working_features_svm =simple_support_vector()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_svm(clf, working_features, normalize = False):\n",
    "\n",
    "    if normalize:\n",
    "        X = normalize_scaler(X_test, working_features=working_features)\n",
    "    else:\n",
    "        X = X_test\n",
    "        \n",
    "    \n",
    "    y_decision_fn_scores = clf.decision_function(X) \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_decision_fn_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plot_auc(y_test, y_decision_fn_scores)\n",
    "    print('Test set AUC: ', roc_auc)\n",
    "            \n",
    "    accuracy_score = clf.score(X, y_test)\n",
    "    \n",
    "    print('Test Accuracy Score: {:.2f}'.format(accuracy_score)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_svm(clf_svm, working_features_svm, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_2D(working_features_svm, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_feature(X, working_features):\n",
    "    X_norm = pd.get_dummies(df[working_features], columns=[\"agency_name\", \"state\",  'violation_code', 'disposition',], prefix=['agency_name', 'state', 'violation_code', 'disposition'])\n",
    "        \n",
    "    return X_norm.ix[X.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def random_forest_solution():\n",
    "    working_features = ['discount_percentage', 'agency_name', 'state', 'violation_code', 'disposition', 'judgment_amount']\n",
    "    \n",
    "    X_norm = normalize_feature(X_work, working_features)\n",
    "    \n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_norm, y_work, random_state=0, test_size=0.1)\n",
    "\n",
    "        \n",
    "    clf = RandomForestClassifier().fit(X_norm, y_work)\n",
    "    \n",
    "#     y_score = clf.decision_function(X_test[working_features])\n",
    "\n",
    "    y_decision_fn_scores = clf.predict_proba(X_validation)[:,1]\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(y_validation, y_decision_fn_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plot_auc(y_validation, y_decision_fn_scores)\n",
    "    \n",
    "#     plot_auc(y_test, y_score)\n",
    "\n",
    "    print('Validation set AUC: ', roc_auc)\n",
    "\n",
    "    accuracy_score = clf.score(X_validation, y_validation)\n",
    "\n",
    "    print('Validation set Accuracy Score: {:.2f}'.format(accuracy_score)) \n",
    "    \n",
    "    return clf, working_features\n",
    "\n",
    "clf_rf, working_features_rf = random_forest_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_tree(clf, working_features, normalize = False):\n",
    "\n",
    "    if normalize:\n",
    "        X = normalize_feature(X_test, working_features=working_features)\n",
    "    else:\n",
    "        X = X_test\n",
    "    \n",
    "    y_decision_fn_scores = clf.predict_proba(X)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_decision_fn_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plot_auc(y_test, y_decision_fn_scores)\n",
    "    print('Test set AUC: ', roc_auc)\n",
    "            \n",
    "    accuracy_score = clf.score(X, y_test)\n",
    "    \n",
    "    print('Test set Accuracy Score: {:.2f}'.format(accuracy_score))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree(clf_rf, working_features_rf, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def tree_auc(estimator, X, y):\n",
    "    y_decision_fn_scores = estimator.predict_proba(X)[:,1]\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(y, y_decision_fn_scores)\n",
    "    \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "def grid_search_tree():\n",
    "    working_features = ['discount_percentage', 'agency_name', 'state', 'violation_code', 'disposition', 'judgment_amount']\n",
    "\n",
    "    X_norm = normalize_feature(X_work, working_features)\n",
    "            \n",
    "    clf = DecisionTreeClassifier()\n",
    "    grid_values = {'max_depth': range(5,20)}\n",
    "    \n",
    "    grid_clf = GridSearchCV(clf, param_grid = grid_values, scoring = tree_auc)\n",
    "    \n",
    "    grid_clf.fit(X_norm, y_work)\n",
    "    \n",
    "    print('Grid best parameter (max. AUC): ', grid_clf.best_params_)\n",
    "    print('Grid best score (AUC): ', grid_clf.best_score_)\n",
    "    print(grid_clf.cv_results_['mean_test_score'])\n",
    "    \n",
    "    return grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_depth = grid_search_tree()['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decision_tree_solution(max_depth):\n",
    "    working_features = ['discount_percentage', 'agency_name', 'state', 'violation_code', 'disposition', 'judgment_amount']\n",
    "    \n",
    "    X_norm = normalize_feature(X_work, working_features)\n",
    "    \n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_norm, y_work, random_state=0, test_size=0.1)\n",
    "        \n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth).fit(X_train, y_train)\n",
    "    \n",
    "    y_decision_fn_scores = clf.predict_proba(X_validation)[:,1]\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(y_validation, y_decision_fn_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plot_auc(y_validation, y_decision_fn_scores)\n",
    "    \n",
    "    print('Validation set AUC: ', roc_auc)\n",
    "\n",
    "    accuracy_score = clf.score(X_validation, y_validation)\n",
    "\n",
    "    print('Validation set Accuracy Score: {:.2f}'.format(accuracy_score))\n",
    "    \n",
    "    expanded_features = X_norm.columns.values\n",
    "    \n",
    "    return clf, working_features, expanded_features\n",
    "\n",
    "clf_dt, working_features_dt, expanded_features_dt = decision_tree_solution(best_tree_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree(clf_dt, working_features_dt, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from adspy_shared_utilities import plot_decision_tree, plot_feature_importances\n",
    "\n",
    "def plot_tree(clf, expanded_features):\n",
    "    importances = clf.feature_importances_\n",
    "    \n",
    "    data = []\n",
    "        \n",
    "    for i in range(len(expanded_features)):\n",
    "        data.append([expanded_features[i], importances[i]])\n",
    "        \n",
    "    result = pd.DataFrame(data, columns=['feature', 'importance'])\n",
    "    \n",
    "    print(result.sort_values('importance', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_tree(clf_dt, expanded_features_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_tree(clf_dt, expanded_features_dt, ['non-compliant', 'compliant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "nNS8l",
   "launcher_item_id": "yWWk7",
   "part_id": "w8BSS"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
